# packages in environment at /cluster/home/gcardenal/miniconda3/envs/vllm_2:
#
# Name                    Version                   Build  Channel
_libgcc_mutex             0.1                        main  
_openmp_mutex             5.1                       1_gnu  
accelerate                1.1.1                    pypi_0    pypi
aiohappyeyeballs          2.4.0                    pypi_0    pypi
aiohttp                   3.10.6                   pypi_0    pypi
aiosignal                 1.3.1                    pypi_0    pypi
annotated-types           0.7.0                    pypi_0    pypi
anthropic                 0.40.0                   pypi_0    pypi
anyio                     4.6.0                    pypi_0    pypi
argon2-cffi               23.1.0                   pypi_0    pypi
argon2-cffi-bindings      21.2.0                   pypi_0    pypi
arrow                     1.3.0                    pypi_0    pypi
asttokens                 3.0.0                    pypi_0    pypi
async-lru                 2.0.4                    pypi_0    pypi
async-timeout             4.0.3                    pypi_0    pypi
attrs                     24.2.0                   pypi_0    pypi
babel                     2.16.0                   pypi_0    pypi
beautifulsoup4            4.12.3                   pypi_0    pypi
bleach                    6.2.0                    pypi_0    pypi
bzip2                     1.0.8                h5eee18b_6  
ca-certificates           2024.7.2             h06a4308_0  
certifi                   2024.8.30                pypi_0    pypi
cffi                      1.17.1                   pypi_0    pypi
charset-normalizer        3.3.2                    pypi_0    pypi
click                     8.1.7                    pypi_0    pypi
cloudpickle               3.0.0                    pypi_0    pypi
comm                      0.2.2                    pypi_0    pypi
datasets                  3.0.1                    pypi_0    pypi
debugpy                   1.8.9                    pypi_0    pypi
decorator                 5.1.1                    pypi_0    pypi
defusedxml                0.7.1                    pypi_0    pypi
dill                      0.3.8                    pypi_0    pypi
diskcache                 5.6.3                    pypi_0    pypi
distro                    1.9.0                    pypi_0    pypi
einops                    0.8.0                    pypi_0    pypi
emoji                     2.14.0                   pypi_0    pypi
exceptiongroup            1.2.2                    pypi_0    pypi
executing                 2.1.0                    pypi_0    pypi
fastapi                   0.115.0                  pypi_0    pypi
fastjsonschema            2.21.1                   pypi_0    pypi
filelock                  3.16.1                   pypi_0    pypi
fqdn                      1.5.1                    pypi_0    pypi
frozenlist                1.4.1                    pypi_0    pypi
fsspec                    2024.6.1                 pypi_0    pypi
gguf                      0.10.0                   pypi_0    pypi
h11                       0.14.0                   pypi_0    pypi
httpcore                  1.0.5                    pypi_0    pypi
httptools                 0.6.1                    pypi_0    pypi
httpx                     0.28.0                   pypi_0    pypi
huggingface-hub           0.25.1                   pypi_0    pypi
idna                      3.10                     pypi_0    pypi
importlib-metadata        8.5.0                    pypi_0    pypi
interegular               0.3.3                    pypi_0    pypi
ipykernel                 6.29.5                   pypi_0    pypi
ipython                   8.30.0                   pypi_0    pypi
ipywidgets                8.1.5                    pypi_0    pypi
isoduration               20.11.0                  pypi_0    pypi
jedi                      0.19.2                   pypi_0    pypi
jinja2                    3.1.4                    pypi_0    pypi
jiter                     0.5.0                    pypi_0    pypi
json5                     0.10.0                   pypi_0    pypi
jsonpointer               3.0.0                    pypi_0    pypi
jsonschema                4.23.0                   pypi_0    pypi
jsonschema-specifications 2023.12.1                pypi_0    pypi
jupyter                   1.1.1                    pypi_0    pypi
jupyter-client            8.6.3                    pypi_0    pypi
jupyter-console           6.6.3                    pypi_0    pypi
jupyter-core              5.7.2                    pypi_0    pypi
jupyter-events            0.10.0                   pypi_0    pypi
jupyter-lsp               2.2.5                    pypi_0    pypi
jupyter-server            2.14.2                   pypi_0    pypi
jupyter-server-terminals  0.5.3                    pypi_0    pypi
jupyterlab                4.3.2                    pypi_0    pypi
jupyterlab-pygments       0.3.0                    pypi_0    pypi
jupyterlab-server         2.27.3                   pypi_0    pypi
jupyterlab-widgets        3.0.13                   pypi_0    pypi
lark                      1.2.2                    pypi_0    pypi
ld_impl_linux-64          2.40                 h12ee557_0  
libffi                    3.4.4                h6a678d5_1  
libgcc-ng                 11.2.0               h1234567_1  
libgomp                   11.2.0               h1234567_1  
libstdcxx-ng              11.2.0               h1234567_1  
libuuid                   1.41.5               h5eee18b_0  
llvmlite                  0.43.0                   pypi_0    pypi
lm-format-enforcer        0.10.6                   pypi_0    pypi
markupsafe                2.1.5                    pypi_0    pypi
matplotlib-inline         0.1.7                    pypi_0    pypi
mistral-common            1.4.3                    pypi_0    pypi
mistune                   3.0.2                    pypi_0    pypi
mpmath                    1.3.0                    pypi_0    pypi
msgpack                   1.1.0                    pypi_0    pypi
msgspec                   0.18.6                   pypi_0    pypi
multidict                 6.1.0                    pypi_0    pypi
multiprocess              0.70.16                  pypi_0    pypi
nbclient                  0.10.1                   pypi_0    pypi
nbconvert                 7.16.4                   pypi_0    pypi
nbformat                  5.10.4                   pypi_0    pypi
ncurses                   6.4                  h6a678d5_0  
nest-asyncio              1.6.0                    pypi_0    pypi
networkx                  3.3                      pypi_0    pypi
notebook                  7.3.1                    pypi_0    pypi
notebook-shim             0.2.4                    pypi_0    pypi
numba                     0.60.0                   pypi_0    pypi
numpy                     1.26.4                   pypi_0    pypi
nvidia-cublas-cu12        12.1.3.1                 pypi_0    pypi
nvidia-cuda-cupti-cu12    12.1.105                 pypi_0    pypi
nvidia-cuda-nvrtc-cu12    12.1.105                 pypi_0    pypi
nvidia-cuda-runtime-cu12  12.1.105                 pypi_0    pypi
nvidia-cudnn-cu12         9.1.0.70                 pypi_0    pypi
nvidia-cufft-cu12         11.0.2.54                pypi_0    pypi
nvidia-curand-cu12        10.3.2.106               pypi_0    pypi
nvidia-cusolver-cu12      11.4.5.107               pypi_0    pypi
nvidia-cusparse-cu12      12.1.0.106               pypi_0    pypi
nvidia-ml-py              12.560.30                pypi_0    pypi
nvidia-nccl-cu12          2.20.5                   pypi_0    pypi
nvidia-nvjitlink-cu12     12.6.68                  pypi_0    pypi
nvidia-nvtx-cu12          12.1.105                 pypi_0    pypi
openai                    1.48.0                   pypi_0    pypi
openssl                   3.0.15               h5eee18b_0  
outlines                  0.0.46                   pypi_0    pypi
overrides                 7.7.0                    pypi_0    pypi
packaging                 24.1                     pypi_0    pypi
pandas                    2.2.3                    pypi_0    pypi
pandocfilters             1.5.1                    pypi_0    pypi
parso                     0.8.4                    pypi_0    pypi
partial-json-parser       0.2.1.1.post4            pypi_0    pypi
pexpect                   4.9.0                    pypi_0    pypi
pillow                    10.4.0                   pypi_0    pypi
pip                       24.2            py310h06a4308_0  
platformdirs              4.3.6                    pypi_0    pypi
plotly                    5.24.1                   pypi_0    pypi
prometheus-client         0.21.0                   pypi_0    pypi
prometheus-fastapi-instrumentator 7.0.0                    pypi_0    pypi
prompt-toolkit            3.0.48                   pypi_0    pypi
protobuf                  5.28.2                   pypi_0    pypi
psutil                    6.0.0                    pypi_0    pypi
ptyprocess                0.7.0                    pypi_0    pypi
pure-eval                 0.2.3                    pypi_0    pypi
py-cpuinfo                9.0.0                    pypi_0    pypi
pyairports                2.1.1                    pypi_0    pypi
pyarrow                   17.0.0                   pypi_0    pypi
pycountry                 24.6.1                   pypi_0    pypi
pycparser                 2.22                     pypi_0    pypi
pydantic                  2.9.2                    pypi_0    pypi
pydantic-core             2.23.4                   pypi_0    pypi
pygments                  2.18.0                   pypi_0    pypi
python                    3.10.14              h955ad1f_1  
python-dateutil           2.9.0.post0              pypi_0    pypi
python-dotenv             1.0.1                    pypi_0    pypi
python-json-logger        2.0.7                    pypi_0    pypi
pytz                      2024.2                   pypi_0    pypi
pyyaml                    6.0.2                    pypi_0    pypi
pyzmq                     26.2.0                   pypi_0    pypi
ray                       2.37.0                   pypi_0    pypi
readline                  8.2                  h5eee18b_0  
referencing               0.35.1                   pypi_0    pypi
regex                     2024.9.11                pypi_0    pypi
requests                  2.32.3                   pypi_0    pypi
rfc3339-validator         0.1.4                    pypi_0    pypi
rfc3986-validator         0.1.1                    pypi_0    pypi
rpds-py                   0.20.0                   pypi_0    pypi
safetensors               0.4.5                    pypi_0    pypi
send2trash                1.8.3                    pypi_0    pypi
sentencepiece             0.2.0                    pypi_0    pypi
setuptools                75.1.0          py310h06a4308_0  
six                       1.16.0                   pypi_0    pypi
sniffio                   1.3.1                    pypi_0    pypi
soupsieve                 2.6                      pypi_0    pypi
sqlite                    3.45.3               h5eee18b_0  
stack-data                0.6.3                    pypi_0    pypi
stanza                    1.9.2                    pypi_0    pypi
starlette                 0.38.6                   pypi_0    pypi
sympy                     1.13.3                   pypi_0    pypi
tenacity                  9.0.0                    pypi_0    pypi
terminado                 0.18.1                   pypi_0    pypi
tiktoken                  0.7.0                    pypi_0    pypi
timm                      1.0.12                   pypi_0    pypi
tinycss2                  1.4.0                    pypi_0    pypi
tk                        8.6.14               h39e8969_0  
tokenizers                0.20.0                   pypi_0    pypi
tomli                     2.2.1                    pypi_0    pypi
torch                     2.4.0                    pypi_0    pypi
torchvision               0.19.0                   pypi_0    pypi
tornado                   6.4.2                    pypi_0    pypi
tqdm                      4.66.5                   pypi_0    pypi
traitlets                 5.14.3                   pypi_0    pypi
transformers              4.45.0                   pypi_0    pypi
triton                    3.0.0                    pypi_0    pypi
types-python-dateutil     2.9.0.20241003           pypi_0    pypi
typing-extensions         4.12.2                   pypi_0    pypi
tzdata                    2024.2                   pypi_0    pypi
uri-template              1.3.0                    pypi_0    pypi
urllib3                   2.2.3                    pypi_0    pypi
uvicorn                   0.30.6                   pypi_0    pypi
uvloop                    0.20.0                   pypi_0    pypi
vllm                      0.6.2                    pypi_0    pypi
watchfiles                0.24.0                   pypi_0    pypi
wcwidth                   0.2.13                   pypi_0    pypi
webcolors                 24.11.1                  pypi_0    pypi
webencodings              0.5.1                    pypi_0    pypi
websocket-client          1.8.0                    pypi_0    pypi
websockets                13.1                     pypi_0    pypi
wheel                     0.44.0          py310h06a4308_0  
widgetsnbextension        4.0.13                   pypi_0    pypi
xformers                  0.0.27.post2             pypi_0    pypi
xxhash                    3.5.0                    pypi_0    pypi
xz                        5.4.6                h5eee18b_1  
yarl                      1.12.1                   pypi_0    pypi
zipp                      3.20.2                   pypi_0    pypi
zlib                      1.2.13               h5eee18b_1  
Package                  Version
------------------------ ---------
anaconda-anon-usage      0.7.0
annotated-types          0.6.0
archspec                 0.2.3
boltons                  24.1.0
Brotli                   1.0.9
certifi                  2025.4.26
cffi                     1.17.1
charset-normalizer       3.3.2
conda                    25.3.1
conda-anaconda-telemetry 0.1.2
conda-anaconda-tos       0.1.3
conda-content-trust      0.2.0
conda-libmamba-solver    25.4.0
conda-package-handling   2.4.0
conda_package_streaming  0.11.0
cryptography             44.0.1
distro                   1.9.0
filelock                 3.18.0
frozendict               2.4.2
fsspec                   2025.5.1
hf-xet                   1.1.2
huggingface-hub          0.32.3
idna                     3.7
jsonpatch                1.33
jsonpointer              2.1
libmambapy               2.0.5
markdown-it-py           2.2.0
mdurl                    0.1.0
menuinst                 2.2.0
numpy                    2.2.6
packaging                24.2
pip                      25.0
platformdirs             4.3.7
pluggy                   1.5.0
pycosat                  0.6.6
pycparser                2.21
pydantic                 2.10.3
pydantic_core            2.27.1
Pygments                 2.19.1
PySocks                  1.7.1
PyYAML                   6.0.2
regex                    2024.11.6
requests                 2.32.3
rich                     13.9.4
ruamel.yaml              0.18.10
ruamel.yaml.clib         0.2.12
safetensors              0.5.3
setuptools               78.1.1
tokenizers               0.21.1
tqdm                     4.67.1
transformers             4.52.4
truststore               0.10.0
typing_extensions        4.12.2
urllib3                  2.3.0
wheel                    0.45.1
zstandard                0.23.0

Currently Loaded Modules:
  1) stack/2024-05   3) cuda/12.2.1          5) eth_proxy   7) hdf5/1.14.3
  2) gcc/13.2.0      4) python/3.11.6_cuda   6) r/4.3.2     8) julia/1.10.3

 

Using Python at: /cluster/home/gcardenal/miniconda3/bin/python
Using torchrun at: /cluster/home/gcardenal/miniconda3/envs/vllm_2/bin/torchrun
Traceback (most recent call last):
  File "<string>", line 1, in <module>
    import openai; print('✅ openai imported successfully')
    ^^^^^^^^^^^^^
ModuleNotFoundError: No module named 'openai'
  File "<string>", line 1
    import os; print(os.environ)')
                                ^
SyntaxError: unterminated string literal (detected at line 1)
None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.
✅ It works
Testing Slurm Variables...
SLURM_JOB_USER=gcardenal
SLURM_TASKS_PER_NODE=1
SLURM_JOB_UID=608619
SLURM_TASK_PID=3127933
SLURM_JOB_GPUS=7
SLURM_LOCALID=0
SLURM_SUBMIT_DIR=/cluster/home/gcardenal/HIV/medical_llm_evaluation/deploy_medical_llm_evaluation
SLURMD_NODENAME=eu-g6-002
SLURM_JOB_START_TIME=1748599293
SLURM_CLUSTER_NAME=euler-24-production
SLURM_JOB_END_TIME=1748685693
SLURM_CPUS_ON_NODE=8
SLURM_JOB_CPUS_PER_NODE=8
SLURM_GPUS_ON_NODE=1
SLURM_GTIDS=0
SLURM_JOB_PARTITION=gpuhe.24h
SLURM_TRES_PER_TASK=cpu=8
SLURM_JOB_NUM_NODES=1
SLURM_JOBID=33479200
SLURM_GPUS=nvidia_geforce_rtx_4090:1
SLURM_JOB_QOS=es_ilic/gpuhe/24
SLURM_PROCID=0
SLURM_CPUS_PER_TASK=8
SLURM_NTASKS=1
SLURM_TOPOLOGY_ADDR=.euler_rtx4090_lca_ib.eu-g6-002
SLURM_TOPOLOGY_ADDR_PATTERN=switch.switch.node
SLURM_MEM_PER_CPU=20480
SLURM_SCRIPT_CONTEXT=prolog_task
SLURM_NODELIST=eu-g6-002
SLURM_JOB_ACCOUNT=gpuhe/es_ilic
SLURM_PRIO_PROCESS=0
SLURM_NPROCS=1
SLURM_NNODES=1
SLURM_SUBMIT_HOST=eu-g5-008-3
SLURM_JOB_ID=33479200
SLURM_NODEID=0
SLURM_CONF=/cluster/slurm/adm/etc/slurm.conf
SLURM_JOB_NAME=final_results
SLURM_JOB_GID=492010
SLURM_JOB_NODELIST=eu-g6-002
Fri May 30 12:01:50 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.133.20             Driver Version: 570.133.20     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 4090        On  |   00000000:E1:00.0 Off |                  Off |
| 31%   35C    P8             23W /  450W |       1MiB /  24564MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Node IP: 10.205.11.85
JobId=33479200 JobName=final_results
   UserId=gcardenal(608619) GroupId=gcardenal-group(492010) MCS_label=N/A
   Priority=4027 Nice=0 Account=gpuhe/es_ilic QOS=es_ilic/gpuhe/24
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:00:17 TimeLimit=1-00:00:00 TimeMin=N/A
   SubmitTime=2025-05-30T12:01:32 EligibleTime=2025-05-30T12:01:32
   AccrueTime=2025-05-30T12:01:32
   StartTime=2025-05-30T12:01:33 EndTime=2025-05-31T12:01:33 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-05-30T12:01:33 Scheduler=Main
   Partition=gpuhe.24h AllocNode:Sid=eu-g5-008-3:1156748
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=eu-g6-002
   BatchHost=eu-g6-002
   NumNodes=1 NumCPUs=8 NumTasks=1 CPUs/Task=8 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=8,mem=160G,node=1,billing=694681,gres/gpu=1,gres/gpu:nvidia_geforce_rtx_4090=1,gres/gpumem=10737418240
   AllocTRES=cpu=8,mem=160G,node=1,billing=694681,gres/gpu=1,gres/gpu:nvidia_geforce_rtx_4090=1,gres/gpumem=0
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:1 CoreSpec=*
   MinCPUsNode=8 MinMemoryCPU=20G MinTmpDiskNode=0
   Features=(null) DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/cluster/home/gcardenal/HIV/medical_llm_evaluation/deploy_medical_llm_evaluation/generate_answers.sh
   WorkDir=/cluster/home/gcardenal/HIV/medical_llm_evaluation/deploy_medical_llm_evaluation
   StdErr=/cluster/home/gcardenal/HIV/medical_llm_evaluation/deploy_medical_llm_evaluation/final_results33479200.out
   StdIn=/dev/null
   StdOut=/cluster/home/gcardenal/HIV/medical_llm_evaluation/deploy_medical_llm_evaluation/final_results33479200.out
   TresPerJob=gres/gpu:nvidia_geforce_rtx_4090:1
   TresPerNode=gres/gpumem:10G
   TresPerTask=cpu=8
   

Running in standalone mode...
I0530 12:01:55.110000 22624952813376 torch/distributed/run.py:881] 
I0530 12:01:55.110000 22624952813376 torch/distributed/run.py:881] **************************************
I0530 12:01:55.110000 22624952813376 torch/distributed/run.py:881] Rendezvous info:
I0530 12:01:55.110000 22624952813376 torch/distributed/run.py:881] --rdzv-backend=c10d --rdzv-endpoint=localhost:0 --rdzv-id=85da42ae-5bcf-44d1-870b-a4f20eb68d95
I0530 12:01:55.110000 22624952813376 torch/distributed/run.py:881] **************************************
I0530 12:01:55.110000 22624952813376 torch/distributed/run.py:881] 
I0530 12:01:55.110000 22624952813376 torch/distributed/launcher/api.py:189] Starting elastic_operator with launch configs:
I0530 12:01:55.110000 22624952813376 torch/distributed/launcher/api.py:189]   entrypoint       : get_model_answers_and_prompt_generation.py
I0530 12:01:55.110000 22624952813376 torch/distributed/launcher/api.py:189]   min_nodes        : 1
I0530 12:01:55.110000 22624952813376 torch/distributed/launcher/api.py:189]   max_nodes        : 1
I0530 12:01:55.110000 22624952813376 torch/distributed/launcher/api.py:189]   nproc_per_node   : 1
I0530 12:01:55.110000 22624952813376 torch/distributed/launcher/api.py:189]   run_id           : 85da42ae-5bcf-44d1-870b-a4f20eb68d95
I0530 12:01:55.110000 22624952813376 torch/distributed/launcher/api.py:189]   rdzv_backend     : c10d
I0530 12:01:55.110000 22624952813376 torch/distributed/launcher/api.py:189]   rdzv_endpoint    : localhost:0
I0530 12:01:55.110000 22624952813376 torch/distributed/launcher/api.py:189]   rdzv_configs     : {'timeout': 900}
I0530 12:01:55.110000 22624952813376 torch/distributed/launcher/api.py:189]   max_restarts     : 0
I0530 12:01:55.110000 22624952813376 torch/distributed/launcher/api.py:189]   monitor_interval : 0.1
I0530 12:01:55.110000 22624952813376 torch/distributed/launcher/api.py:189]   log_dir          : /scratch/tmp.33479200.gcardenal/torchelastic_rjei814l
I0530 12:01:55.110000 22624952813376 torch/distributed/launcher/api.py:189]   metrics_cfg      : {}
I0530 12:01:55.110000 22624952813376 torch/distributed/launcher/api.py:189] 
I0530 12:01:55.122000 22624952813376 torch/distributed/elastic/agent/server/api.py:825] [default] starting workers for entrypoint: python
I0530 12:01:55.122000 22624952813376 torch/distributed/elastic/agent/server/api.py:646] [default] Rendezvous'ing worker group
I0530 12:01:55.310000 22624952813376 torch/distributed/elastic/agent/server/api.py:512] [default] Rendezvous complete for workers. Result:
I0530 12:01:55.310000 22624952813376 torch/distributed/elastic/agent/server/api.py:512]   restart_count=0
I0530 12:01:55.310000 22624952813376 torch/distributed/elastic/agent/server/api.py:512]   master_addr=eu-g6-002.euler.ethz.ch
I0530 12:01:55.310000 22624952813376 torch/distributed/elastic/agent/server/api.py:512]   master_port=42733
I0530 12:01:55.310000 22624952813376 torch/distributed/elastic/agent/server/api.py:512]   group_rank=0
I0530 12:01:55.310000 22624952813376 torch/distributed/elastic/agent/server/api.py:512]   group_world_size=1
I0530 12:01:55.310000 22624952813376 torch/distributed/elastic/agent/server/api.py:512]   local_ranks=[0]
I0530 12:01:55.310000 22624952813376 torch/distributed/elastic/agent/server/api.py:512]   role_ranks=[0]
I0530 12:01:55.310000 22624952813376 torch/distributed/elastic/agent/server/api.py:512]   global_ranks=[0]
I0530 12:01:55.310000 22624952813376 torch/distributed/elastic/agent/server/api.py:512]   role_world_sizes=[1]
I0530 12:01:55.310000 22624952813376 torch/distributed/elastic/agent/server/api.py:512]   global_world_sizes=[1]
I0530 12:01:55.310000 22624952813376 torch/distributed/elastic/agent/server/api.py:512] 
I0530 12:01:55.310000 22624952813376 torch/distributed/elastic/agent/server/api.py:654] [default] Starting worker group
I0530 12:01:55.310000 22624952813376 torch/distributed/elastic/agent/server/local_elastic_agent.py:185] Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
I0530 12:01:55.310000 22624952813376 torch/distributed/elastic/agent/server/local_elastic_agent.py:217] Environment variable 'TORCHELASTIC_HEALTH_CHECK_PORT' not found. Do not start health check.
Traceback (most recent call last):
  File "/cluster/home/gcardenal/HIV/medical_llm_evaluation/deploy_medical_llm_evaluation/get_model_answers_and_prompt_generation.py", line 14, in <module>
    from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig, pipeline, Gemma3ForCausalLM
ImportError: cannot import name 'Gemma3ForCausalLM' from 'transformers' (/cluster/home/gcardenal/miniconda3/envs/vllm_2/lib/python3.10/site-packages/transformers/__init__.py)
E0530 12:02:03.029000 22624952813376 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 3133157) of binary: /cluster/home/gcardenal/miniconda3/envs/vllm_2/bin/python
I0530 12:02:03.042000 22624952813376 torch/distributed/elastic/multiprocessing/errors/__init__.py:361] ('local_rank %s FAILED with no error file. Decorate your entrypoint fn with @record for traceback info. See: https://pytorch.org/docs/stable/elastic/errors.html', 0)
Traceback (most recent call last):
  File "/cluster/home/gcardenal/miniconda3/envs/vllm_2/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/cluster/home/gcardenal/miniconda3/envs/vllm_2/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
  File "/cluster/home/gcardenal/miniconda3/envs/vllm_2/lib/python3.10/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/cluster/home/gcardenal/miniconda3/envs/vllm_2/lib/python3.10/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/cluster/home/gcardenal/miniconda3/envs/vllm_2/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/cluster/home/gcardenal/miniconda3/envs/vllm_2/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
get_model_answers_and_prompt_generation.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-05-30_12:02:03
  host      : eu-g6-002.euler.ethz.ch
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 3133157)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
srun: error: eu-g6-002: task 0: Exited with exit code 1
